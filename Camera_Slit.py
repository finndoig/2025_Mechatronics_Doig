# This is the vision library OpenCV
import cv2
# This is a library for mathematical functions for python (used later)
import numpy as np
# This is a library to get access to time-related functionalities
import time
# This is the Aruco library from OpenCV
import cv2.aruco as aruco 
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')

Camera=np.load('Calibration.npz') #Load the camera calibration values 
CM=Camera['CM'] #camera matrix 
dist_coef=Camera['dist_coef']# distortion coefficients from the camera 

# load CharacterColours array
from CharacterColours import get_characters

chars = get_characters()
print(chars)   # -> ['Character1', 'Character2', 'Character3', 'Character4']
Character1 = chars[0]
Character2 = chars[1]
Character3 = chars[2]
Character4 = chars[3]

# Select the first camera (0) that is connected to the machine
# in Laptops should be the build-in camera
cap = cv2.VideoCapture(1)
 
# Set the width and heigth of the camera to 1920x1080
cap.set(3,1920)
cap.set(4,1080)

#Create frame and slit opencv named windows
cv2.namedWindow("frame-image", cv2.WINDOW_AUTOSIZE)
cv2.namedWindow("slit-image", cv2.WINDOW_AUTOSIZE)

#Position the windows ontop of eachother
cv2.moveWindow("frame-image",0,100)
cv2.moveWindow("slit-image",960,100)

# Execute this continuously
while(True):
    
    # Start the performance clock
    start = time.perf_counter()
    
    # Capture current frame from the camera
    ret, frame = cap.read()

    # --- central slit extraction ---
    # Change this value to control how many pixels wide the slit is
    SLIT_Height = 3  # pixels (odd number keeps perfect centering)

    # image dimensions
    w, h = frame.shape[:2]
    cy = h // 2
    half = SLIT_Height // 2
    # y0 = max(cy - half, 0)
    # y1 = min(cy + half + (SLIT_Height % 2), h)
    y0 = cy - half
    y1 = cy + half

    # extract a thin vertical slit centered horizontally
    slit_frame = frame[:, y0:y1]
    # small visualization helper: stretch slit horizontally for display
    # slit_vis = cv2.resize(slit_gray, (w, 200), interpolation=cv2.INTER_NEAREST)
    # --- end slit extraction ---

    # Display the original full frame in a window
    cv2.imshow('frame-image', frame)
    cv2.imshow('slit-image', slit_frame)

    # Stop the performance counter
    end = time.perf_counter()
    
    # Print to console the execution time in FPS (frames per second)
    # fps = 1.0 / (end - start) if end > start else 0.0
    # logging.info("FPS: %.1f", fps)

    # these lines were generated by ChatGPT based on the CharacterColours.py structure
    # check whether any pixel in the slit matches Character1 color range and tint the slit red if so
    char_arr = np.asarray(Character4)
    print("Character2 array:", char_arr)

    # try to interpret Character1 as numeric color specification
    lower = upper = None
    try:
        nums = char_arr.astype(np.int32).flatten()
        if nums.size == 6:
            # [Rmin, Gmin, Bmin, Rmax, Gmax, Bmax] or similar -> treat as RGB min/max
            lower = np.array(nums[:3], dtype=np.uint8)
            upper = np.array(nums[3:6], dtype=np.uint8)
        elif nums.size == 3:
            # single RGB center -> use a tolerance
            tol = np.array([20, 20, 20], dtype=np.int32)
            center = nums[:3]
            lower = np.clip(center - tol, 0, 255).astype(np.uint8)
            upper = np.clip(center + tol, 0, 255).astype(np.uint8)
        elif nums.ndim == 1 and nums.size >= 3:
            # fallback: take min/max of first two 3-tuples if present
            lower = np.min(nums.reshape(-1, 3)[:2], axis=0).astype(np.uint8)
            upper = np.max(nums.reshape(-1, 3)[:2], axis=0).astype(np.uint8)
        print("Interpreted Character1 color range:", lower, upper)
    except Exception:
        lower = upper = None

    if lower is not None and upper is not None:
        # convert slit to RGB (user specified RGB ranges) and check in-range
        try:
            rgb_slit = cv2.cvtColor(slit_frame, cv2.COLOR_BGR2RGB)
            print("Converted slit to RGB for color checking.", rgb_slit)
        except Exception:
            rgb_slit = slit_frame.copy()  # fallback if conversion fails

        mask = cv2.inRange(rgb_slit, lower, upper)  # mask where pixels fall inside [lower,upper] in RGB

        if np.any(mask):
            # tint matched pixels to red: convert BGR->HSV, set hue to red and max sat/val where mask true
            hsv = cv2.cvtColor(slit_frame, cv2.COLOR_BGR2HSV)
            hsv[..., 0][mask > 0] = 0    # H = 0 -> red
            hsv[..., 1][mask > 0] = 255  # full saturation
            hsv[..., 2][mask > 0] = 255  # full value
            slit_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        # update the displayed slit image with possibly modified slit_frame
        cv2.imshow('slit-image', slit_frame)
    # end of Character1 color check



    # If the button q is pressed in one of the windows 
    if cv2.waitKey(20) & 0xFF == ord('q'):
        # Exit the While loop
        break
    

# When everything done, release the capture
cap.release()
# close all windows
cv2.destroyAllWindows()
# exit the kernel
exit(0)